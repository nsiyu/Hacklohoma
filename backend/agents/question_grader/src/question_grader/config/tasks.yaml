code_scoring_task:
  description: >
    Grade the candidate code for the coding question:  
    For the coding question: 
    CODING QUESTION BEGIN ---- 
      title: {title}
      description: {description}
      difficulty: {difficulty}
      examples: {examples}
      constraints: {constraints}
    CODING QUESTION END ---- 

    CANDIDATE CODE BEGIN ---- 
    candidate code: {code}
    CANDIDATE CODE END ----


    Score data structure and algorithms coding interviews in scoring categoies: correctness_score, syntax_score, completeness_score, and optimality_score.
    when grading for correctness your main goal is to assess if the algorithm solves the question correctly and accounts for all edge cases.
    When grading syntax you make sure all the syntax is correct for the respective coding language. You can ignore import statements and namespace specifications.
    When grading completeness you make sure the code includes all components for it to be runable. 
    When grading for optimality you make sure the candidate comes up with the most optimal solution (time and space) for the problem. You can ignore niche algorithms that have the most optimal time. 
    So if the candidate has a pretty good time complexity, but there is a niche algorithm with better time complexity, don't deduct points.
    The scores should be numerical values between 0 and 5 with 1 point granularity.

  expected_output: >
    The response should be a valid object that can be parsed into the specified format.
    Make sure to include all required fields and follow the exact structure.
  agent: technical_question_grader

strengths_feedback_task:
  description: >

    Give feedback to the candidate based on their code for the coding question:  
    CODING QUESTION BEGIN ---- 
      title: {title}
      description: {description}
      difficulty: {difficulty}
      examples: {examples}
      constraints: {constraints}
    CODING QUESTION END ---- 

    CANDIDATE CODE BEGIN ---- 
    candidate code: {code}
    CANDIDATE CODE END ----

    The feedback should include relevant info relating to the problem and the candidate submitted code. 
    The feedback should include:
    key_strengths: A list of strings for candidate key strengths (list size between 1 to 5, each less than 3 words) For example: Problem Understanding or Code Organization. 
    areas_to_focus: A list of strings for areas the candidate should focus on (list size between 1 to 5, each less than 3 words). For example: Edge Case Handling or Solution Planning.
    recommended_practice_topics: A list of for recommended practice topics for the candidate (list size between 1 to 5, each less than 3 words). For example: Two-Pointers or Array Manipulation. 
    improvement_feedback_plan: A list of strings of a step by step plan to improve with each list item being a step (list size between 1 to 5)

  expected_output: >
    The response should be a valid object that can be parsed into the specified format.
    Make sure to include all required fields and follow the exact structure.
  agent: technical_question_grader

feedback_generation_task:
  description: >
    Use the software engineer interviewer's scoring and the interview transcript to provide an interview report.
    Provide the same numerical scores provided by the software engineer interviewer and also provide text summaries for overall interview feedback, candidate's behavioral and communication skills feedback,
    and interviewer's feedback for how the candidate can improve. Keep your summaries to less than 4 sentences.

    TRANSCRIPT BEING----
    {transcript}
    TRANSCRIPT END----
  expected_output: >
    The response should be a valid object that can be parsed into the specified format.
    Make sure to include all required fields and follow the exact structure.

  agent: recruiter_agent
